{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4a43423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def confusion_matrix(y_true, y_pred,normalize=None):\n",
    "    \"\"\"Computes the confusion matrix from predictions and labels.\n",
    "\n",
    "    The matrix columns represent the real labels and the rows represent the\n",
    "    prediction labels. The confusion matrix is always a 2-D array of shape `[n_labels, n_labels]`,\n",
    "    where `n_labels` is the number of valid labels for a given classification task. Both\n",
    "    prediction and labels must be 1-D arrays of the same shape in order for this\n",
    "    function to work.\n",
    "\n",
    "    Parameters:\n",
    "        y_true: 1-D array of real labels for the classification task.\n",
    "        y_pred: 1-D array of predictions for a given classification.\n",
    "        normalize: One of ['true', 'pred', 'all', None], corresponding to column sum, row sum, matrix sum, or no\n",
    "                   normalization.\n",
    "\n",
    "    Returns:\n",
    "        A 2-D array with shape `[n_labels, n_labels]` representing the confusion\n",
    "        matrix, where `n` is the number of possible labels in the classification\n",
    "        task.\n",
    "    \"\"\"\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    N_ele = np.unique(x)\n",
    "    N_Len = len(N_ele)\n",
    "    cm = np.zeros((N_Len,1))\n",
    "    \n",
    "    for i in range(N_Len):\n",
    "        temp = y[x==N_ele[i]]\n",
    "        emt_hist = np.zeros((N_Len,1))\n",
    "        Hist = np.asarray(np.unique(temp, return_counts=True)).T\n",
    "        temp_hist_r1 = Hist[:,0].reshape((len(Hist[:,0]), 1))\n",
    "        temp_hist_r2 = Hist[:,1].reshape((len(Hist[:,0]), 1))\n",
    "        emt_hist[temp_hist_r1[:,0]] = temp_hist_r2\n",
    "        emt_hist = emt_hist.reshape((len(emt_hist), 1))\n",
    "        cm = np.hstack((cm, emt_hist))\n",
    "\n",
    "    cm = np.delete(cm, 0, axis=1)\n",
    "    cm = np.transpose(cm)\n",
    "\n",
    "    if normalize not in ['true', 'pred', 'all', None]:\n",
    "        raise ValueError(\"normalize must be one of {'true', 'pred', 'all', None}\")\n",
    "\n",
    "    if normalize == 'true':\n",
    "        cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    elif normalize == 'pred':\n",
    "        cm = cm / cm.sum(axis=0, keepdims=True)\n",
    "    elif normalize == 'all':\n",
    "        cm = cm / cm.sum()\n",
    "        # TODO (TASK 1)\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred,normalize='pred')\n",
    "    p = cm.diagonal()\n",
    "    return p\n",
    "    # TODO (TASK 2)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred,normalize='true')\n",
    "    r = cm.diagonal()\n",
    "    return r\n",
    "    # TODO (TASK 2)\n",
    "\n",
    "\n",
    "def false_alarm_rate(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "    #FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    #TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    FAR = FP/(TP+FP)\n",
    "    return FAR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1841071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load datasets.py\n",
    "import os\n",
    "import ssl\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def download_and_prepare(name, path):\n",
    "    if name == \"movielens-small\":\n",
    "        print(f\"Preparing dataset {name}...\")\n",
    "        # Check if data has been extracted and if not download extract it\n",
    "        if (os.path.exists(os.path.join(path, \"ml-latest-small\"))):\n",
    "            print(f\"Dataset {name} already extracted.\")\n",
    "        else:\n",
    "            print(f\"Downloading dataset {name}...\")\n",
    "            ssl._create_default_https_context = ssl._create_unverified_context\n",
    "            url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "            wget.download(url, path)\n",
    "            print(f\"Extracting dataset {name}...\")\n",
    "            with zipfile.ZipFile(os.path.join(path, \"ml-latest-small.zip\"), 'r') as zip_ref:\n",
    "                zip_ref.extractall(path)\n",
    "\n",
    "        # Read dataset with pandas\n",
    "        ratings = pd.read_csv(os.path.join(path, 'ml-latest-small', 'ratings.csv'))\n",
    "        print(f\"{len(ratings)} entries read.\")\n",
    "        r_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "        return np.array(r_matrix) # for performance reasons we only take every 2nd element along each axis\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38689a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset movielens-small...\n",
      "Dataset movielens-small already extracted.\n",
      "100836 entries read.\n"
     ]
    }
   ],
   "source": [
    "X = download_and_prepare('movielens-small', 'D:/SEM 2/DPR/Programming/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f807821",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4041716692.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.split = # TODO (TASK 1)\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %load recommender_system.py\n",
    "import numpy as np\n",
    "\n",
    "class MatrixFactorization(object):\n",
    "    \"\"\"Matrix factorization for movie recommendations.\n",
    "\n",
    "    Parameters:\n",
    "        R (ndarray): ratings matrix (0 for no ratings, 1-5 if a rating exists)\n",
    "        factors (int): number of factors for matrix factorization\n",
    "        steps (int): number of steps to perform during training\n",
    "        lr (float): learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, R, factors=5, steps=1000, lr=1e-4):\n",
    "        self.R = R\n",
    "        self.factors = factors\n",
    "        self.steps = steps\n",
    "        self.lr = lr\n",
    "\n",
    "        # Generate mask for known entries (non-zero elements), split the mask into a train and test mask\n",
    "        self.mask = np.ones(R.shape)# TODO (TASK 1)\n",
    "        self.split = # TODO (TASK 1)\n",
    "        self.mask_train = # TODO (TASK 1)\n",
    "        self.mask_test = # TODO (TASK 1)\n",
    "        print(f\"Known entries: {self.mask.sum()}, {self.mask_train.sum()} used for training and {self.mask_test.sum()} used for testing.\")\n",
    "\n",
    "        # Initialize low-rank user and movie matrix uniformly between 0 and 1\n",
    "        self.U = np.random.rand(self.R.shape[0], self.factors).astype(dtype='float32')\n",
    "        self.V = np.random.rand(self.R.shape[1], self.factors).astype(dtype='float32')\n",
    "\n",
    "        # Compute total amount of parameters that have to be estimated\n",
    "        total_parameters = self.U.reshape(-1).size + self.V.reshape(-1).size\n",
    "        print(f\"User matrix shape: {self.U.shape}, movie matrix shape: {self.V.shape}, total parameters: {total_parameters}\")\n",
    "\n",
    "    def gradient_user_matrix(self, error):\n",
    "        return # TODO (TASK 2)\n",
    "\n",
    "    def gradient_movie_matrix(self, error):\n",
    "        return # TODO (TASK 2)\n",
    "\n",
    "    def update_user_matrix(self, u_grad):\n",
    "        self.U = # TODO (TASK 3)\n",
    "\n",
    "    def update_movie_matrix(self, v_grad):\n",
    "        self.V = # TODO (TASK 3)\n",
    "\n",
    "    def rmse(self, split='all'):\n",
    "        if split == 'train':\n",
    "            rmse = np.sqrt(np.sum(self.mask_train * (self.R - np.matmul(self.U, self.V.T)) ** 2) / np.sum(self.mask_train))\n",
    "        elif split == 'test':\n",
    "            rmse = np.sqrt(np.sum(self.mask_test * (self.R - np.matmul(self.U, self.V.T)) ** 2) / np.sum(self.mask_test))\n",
    "        else:\n",
    "            rmse = np.sqrt(np.sum(self.mask * (self.R - np.matmul(self.U, self.V.T)) ** 2) / np.sum(self.mask))\n",
    "        return rmse\n",
    "\n",
    "    def fit(self):\n",
    "        for i in range(self.steps):\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Step {i}/{self.steps}, RMSE (train): {self.rmse('train'):.4f}, RMSE (test): {self.rmse('test'):.4f}\")\n",
    "\n",
    "            error = # TODO (TASK 2) # Compute the error outside the gradient computation, so we don't have to do it twice\n",
    "            u_grad = self.gradient_user_matrix(error)\n",
    "            v_grad = self.gradient_movie_matrix(error)\n",
    "            self.update_user_matrix(u_grad)\n",
    "            self.update_movie_matrix(v_grad)\n",
    "\n",
    "        print(f\"Step {self.steps}/{self.steps}, RMSE (train): {self.rmse('train'):.4f}, RMSE (test): {self.rmse('test'):.4f}\")\n",
    "\n",
    "        return np.matmul(self.U, self.V.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829be064",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (recommender_system.py, line 20)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3505\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 5\u001b[1;36m\n\u001b[1;33m    from recommender_system import MatrixFactorization\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Notebooks_python\\1.Recomender system\\recommender_system.py:20\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.split = # TODO (TASK 1)\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "from metrics import confusion_matrix, precision, recall, false_alarm_rate\n",
    "from datasets import download_and_prepare\n",
    "from recommender_system import MatrixFactorization\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    np.set_printoptions(precision=2, floatmode='fixed')\n",
    "\n",
    "    # Part I\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"Part I - Confusion matrix\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "    y_true = np.random.randint(0, 2, 20)\n",
    "    y_pred = np.random.randint(0, 2, 20)\n",
    "\n",
    "    print(\"Unnormalized confusion matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    print(\"Matrix sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print(cm)\n",
    "    print(\"Row sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='pred')\n",
    "    print(cm)\n",
    "    print(\"Column sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    print(cm)\n",
    "    print(f\"Precision: {precision(y_true, y_pred):.2f}, recall: {recall(y_true, y_pred):.2f}\"\n",
    "          f\", false alarm rate: {false_alarm_rate(y_true, y_pred):.2f}\")\n",
    "\n",
    "'''    # Part II\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"Part II - Movie Recommender System\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "    X = download_and_prepare('movielens-small', '../datasets')\n",
    "    matrixFactor = MatrixFactorization(X)\n",
    "    r_hat = matrixFactor.fit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190ed876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from metrics import confusion_matrix, precision, recall, false_alarm_rate\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    np.set_printoptions(precision=2, floatmode='fixed')\n",
    "\n",
    "    # Part I\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"Part I - Confusion matrix\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "    y_true = np.random.randint(0, 2, 20)\n",
    "    y_pred = np.random.randint(0, 2, 20)\n",
    "\n",
    "    print(\"Unnormalized confusion matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    print(\"Matrix sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print(cm)\n",
    "    print(\"Row sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='pred')\n",
    "    print(cm)\n",
    "    print(\"Column sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    print(cm)\n",
    "    print('Precision:' , precision(y_true, y_pred), '\\nRecall:',recall(y_true, y_pred), '\\nFalse alarm rate:', false_alarm_rate(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f907eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Part I - Confusion matrix\n",
      "------------------------------------------------\n",
      "Unnormalized confusion matrix:\n",
      "[[4.00 9.00]\n",
      " [3.00 4.00]]\n",
      "Matrix sum normalization:\n",
      "[[0.20 0.45]\n",
      " [0.15 0.20]]\n",
      "Row sum normalization:\n",
      "[[0.57 0.69]\n",
      " [0.43 0.31]]\n",
      "Column sum normalization:\n",
      "[[0.31 0.69]\n",
      " [0.43 0.57]]\n",
      "Precision: [0.57 0.31] \n",
      "Recall: [0.31 0.57] \n",
      "False alarm rate: [0.43 0.69]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed39640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
