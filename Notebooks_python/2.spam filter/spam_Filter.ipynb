{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4e5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data and preprocessing it for calculating prediciton probability\n",
    "\n",
    "import os\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "from absl import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def download_and_prepare(name, path):\n",
    "    if name == \"sms_spam\":\n",
    "        logging.info(f\"Preparing dataset {name}...\")\n",
    "        # Check if data has been extracted and if not download extract it\n",
    "        if (os.path.exists(os.path.join(path, \"SMSSpamCollection\"))):\n",
    "            logging.info(f\"Dataset {name} already extracted.\")\n",
    "        else:\n",
    "            logging.info(f\"Downloading dataset {name}...\")\n",
    "            url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
    "            wget.download(url, path)\n",
    "            logging.info(f\"Extracting dataset {name}...\")\n",
    "            with zipfile.ZipFile(os.path.join(path, \"smsspamcollection.zip\"), 'r') as zip_ref:\n",
    "                zip_ref.extractall(os.path.join(path, \"SMSSpamCollection\"))\n",
    "\n",
    "        # Read dataset with pandas\n",
    "        dataset = pd.read_csv(os.path.join(path, \"SMSSpamCollection\", \"SMSSpamCollection\"), delimiter=\"\\t\", encoding=\"latin-1\", header=None)\n",
    "        logging.debug(f\"{len(dataset)} entries read.\")\n",
    "\n",
    "        # Preprocessing\n",
    "        dataset[2] = dataset[0].map({'ham': 0, 'spam': 1})\n",
    "        X, y = dataset[1].values, dataset[2].values\n",
    "        vect = CountVectorizer(stop_words='english')\n",
    "        vect.fit(X)\n",
    "        #print(\"Vocabulary: \", len(vect.vocabulary_))\n",
    "        X = vect.transform(X).toarray()\n",
    "        #print(dataset)\n",
    "        #print(vect)\n",
    "        # Train-test-split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a78a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the above dataset and the diamention of the data set\n",
    "\n",
    "X_train, X_test, y_train, y_test = download_and_prepare(\"sms_spam\", \"D:/SEM 2/DPR/Programming/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6321fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86717523 0.13282477]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = download_and_prepare(\"sms_spam\", \"D:/SEM 2/DPR/Programming/\")\n",
    "alpha = 0.01 #smoothing factor to avoid dividing by zero\n",
    "n_alpha = 10\n",
    "# if alpha is chosen to be 1 then it is called as laplace smoothing\n",
    "# multiply the alpha with n to compensate the addition that has happened in in the numerator  \n",
    "classess = np.unique(y_train)\n",
    "priorir = np.ones(len(classess))\n",
    "#calculation of priori \n",
    "for i in range(len(classess)):\n",
    "    priorir[i] = len(y_train[y_train==classess[i]])/len(y_train)\n",
    "\n",
    "#calculation of likelihood\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P_t_H = X_train[y_train==0]\n",
    "P_t_S = X_train[y_train==1]\n",
    "P_t_H = (np.sum(P_t_H,axis = 0)+0.01)/len(y_train[y_train==0])\n",
    "P_t_S = (np.sum(P_t_S,axis = 0)+0.01)/len(y_train[y_train==1])\n",
    "\n",
    "\n",
    "P_t_H = np.log(P_t_H)\n",
    "P_t_S = np.log(P_t_S)\n",
    "#trying out the priori\n",
    "print(priorir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1259975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defineing the classifier type and implementing the naive bayes method for prediction \n",
    "\n",
    "from absl import logging\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class SpamClassifier(object):\n",
    "    \"\"\"\n",
    "    Spam classifier using (multinomial) Naive Bayes\n",
    "\n",
    "    Parameters:\n",
    "        alpha (float): Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1.0):\n",
    "        super(SpamClassifier, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Training method\n",
    "\n",
    "        Estimates the log-likelihoods and priors for both classes ham and spam.\n",
    "\n",
    "        Parameters:\n",
    "            X (ndarray): Feature matrix with shape (num_samples, num_features)\n",
    "            y (ndarray): Label vector with shape (num_samples,)\n",
    "        \"\"\"\n",
    "        logging.info(f\"Starting training...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        print(X.shape)\n",
    "        self.classes = np.unique(y)\n",
    "        self.n_classes = len(self.classes)\n",
    "\n",
    "        self.priors = np.ones((self.n_classes,)) / self.n_classes # This is just a placeholder\n",
    "        \n",
    "        # X_train, X_test, y_train, y_test = download_and_prepare(\"sms_spam\", \"/home/dearadhp/\")\n",
    "        alpha = 0.01 #smoothing factor to avoid dividing by zero\n",
    "        n_alpha = self.n_classes\n",
    "        # if alpha is chosen to be 1 then it is called as laplace smoothing\n",
    "        # multiply the alpha with n to compensate the addition that has happened in in the numerator  \n",
    "        X_train = X\n",
    "        y_train = y\n",
    "        #calculation of priori \n",
    "        for i in range(self.n_classes):\n",
    "            self.priors[i] = len(y_train[y_train==self.classes[i]])/len(y_train)\n",
    "        print(self.priors)\n",
    "\n",
    "        \n",
    "        # TODO: Estimate priors\n",
    "        self.log_priors = np.log(self.priors)\n",
    "\n",
    "        self.log_probs = np.zeros((self.n_classes, n_features))\n",
    "        temp = np.zeros((1, n_features))\n",
    "        print(self.log_probs.shape)\n",
    "        for i in range(self.n_classes):\n",
    "            #calculation of likelihood\n",
    "            #calculation of log likelihood  \n",
    "            P_t_H = X_train[y_train==self.classes[i]]\n",
    "            P_t_H = (np.sum(P_t_H,axis = 0)+alpha)/(len(y_train[y_train==self.classes[i]])+n_alpha)\n",
    "            P_t_H = np.log(P_t_H)\n",
    "            temp = np.vstack((temp,P_t_H))\n",
    "        self.log_probs = temp[(1,self.n_classes),:]\n",
    "            #print(np.unique(P_t_H))\n",
    "        #print(np.unique(self.log_probs))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # TODO: Estimate log-likelihoods\n",
    "\n",
    "        logging.debug(f\"Training took {int(time.time() - start_time)} seconds.\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Prediction method\n",
    "\n",
    "        Uses Bayes rule to compute un-normalized posteriors\n",
    "        \n",
    "        \n",
    "\n",
    "        Parameters:\n",
    "            X (ndarray): Feature matrix with shape (num_samples, num_features)\n",
    "\n",
    "        Returns:\n",
    "            (ndarray): Prediction vector with shape (num_samples,)\n",
    "        \"\"\"\n",
    "        # TODO: Implement MAP decision for multinomial Naive Bayes\n",
    "        pri = np.matmul(self.log_probs, np.transpose(X))\n",
    "        esti = pri.max(axis = 0)\n",
    "        \"\"\"for i in range(len(esti)):\n",
    "            print(pri[:,i])\n",
    "            print(esti[i]) \"\"\"\n",
    "        \n",
    "        esti_class = np.argmax(pri, axis=0)\n",
    "        '''for i in range(len(esti_class)):\n",
    "            print(esti_class[i])\n",
    "        print(len(esti_class))\n",
    "        #print()'''\n",
    "        #np.zeros(X.shape[0]) # This is just a placeholder in the return\n",
    "        return esti_class\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eeae750e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Preparing dataset sms_spam...\n",
      "INFO:absl:Dataset sms_spam already extracted.\n",
      "DEBUG:absl:5572 entries read.\n",
      "INFO:absl:Starting training...\n",
      "DEBUG:absl:Training took 0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 8480)\n",
      "[0.86717523 0.13282477]\n",
      "(2, 8480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the data and applying the classifier\n",
    "X_train, X_test, y_train, y_test = download_and_prepare(\"sms_spam\", \"D:/SEM 2/DPR/Programming/\")\n",
    "\n",
    "spam_classifier = SpamClassifier()\n",
    "spam_classifier.train(X_train, y_train)\n",
    "spam_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbba9325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "            print(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6da20fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Preparing dataset sms_spam...\n",
      "INFO:absl:Dataset sms_spam already extracted.\n",
      "DEBUG:absl:5572 entries read.\n",
      "INFO:absl:Starting training...\n",
      "DEBUG:absl:Training took 0 seconds.\n",
      "INFO:absl:Train Accuracy: 0.8658290329818263\n",
      "INFO:absl:Test Accuracy: 0.8663677130044843\n"
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "from absl import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datasets import download_and_prepare\n",
    "from classifier import SpamClassifier\n",
    "\n",
    "\n",
    "def main():\n",
    "    X_train, X_test, y_train, y_test = download_and_prepare(\"sms_spam\", \"D:/SEM 2/DPR/Programming/\")\n",
    "\n",
    "    spam_classifier = SpamClassifier()\n",
    "    spam_classifier.train(X_train, y_train)\n",
    "\n",
    "    logging.info(f\"Train Accuracy: {accuracy_score(y_train, spam_classifier.predict(X_train))}\")\n",
    "    logging.info(f\"Test Accuracy: {accuracy_score(y_test, spam_classifier.predict(X_test))}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.set_verbosity(logging.DEBUG)\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d794a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec2aed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cda8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864a798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d847d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7ed5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
