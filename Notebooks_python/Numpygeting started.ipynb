{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fe229574",
   "metadata": {},
   "source": [
    "#List are good but they are not good enouggh for doing matrix operations therefore go for the numpy\n",
    "# also numpy array are faster \n",
    "# Should avoid extending the array in loop because it creates a new array every loop and too much memory\n",
    "# but if the final shape and size fo the array is know then create an empty array and use it in the loop \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05f6e6a6",
   "metadata": {},
   "source": [
    "Broadcasting \n",
    "this is to understand how the array operation are conducted by numpy its not by python but by the C (if they are in loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7f1d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_true = np.array([1,0,2,1,1,2,0,1,2,1])\n",
    "y_pred = np.array([1,2,0,1,0,2,0,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ab6b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def confusion_matrix(y_true, y_pred,normalize=None):\n",
    "    \"\"\"Computes the confusion matrix from predictions and labels.\n",
    "\n",
    "    The matrix columns represent the real labels and the rows represent the\n",
    "    prediction labels. The confusion matrix is always a 2-D array of shape `[n_labels, n_labels]`,\n",
    "    where `n_labels` is the number of valid labels for a given classification task. Both\n",
    "    prediction and labels must be 1-D arrays of the same shape in order for this\n",
    "    function to work.\n",
    "\n",
    "    Parameters:\n",
    "        y_true: 1-D array of real labels for the classification task.\n",
    "        y_pred: 1-D array of predictions for a given classification.\n",
    "        normalize: One of ['true', 'pred', 'all', None], corresponding to column sum, row sum, matrix sum, or no\n",
    "                   normalization.\n",
    "\n",
    "    Returns:\n",
    "        A 2-D array with shape `[n_labels, n_labels]` representing the confusion\n",
    "        matrix, where `n` is the number of possible labels in the classification\n",
    "        task.\n",
    "    \"\"\"\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    N_ele = np.unique(x)\n",
    "    N_Len = len(N_ele)\n",
    "    cm = np.zeros((N_Len,1))\n",
    "    \n",
    "    for i in range(N_Len):\n",
    "        temp = y[x==N_ele[i]]\n",
    "        emt_hist = np.zeros((N_Len,1))\n",
    "        Hist = np.asarray(np.unique(temp, return_counts=True)).T\n",
    "        temp_hist_r1 = Hist[:,0].reshape((len(Hist[:,0]), 1))\n",
    "        temp_hist_r2 = Hist[:,1].reshape((len(Hist[:,0]), 1))\n",
    "        emt_hist[temp_hist_r1[:,0]] = temp_hist_r2\n",
    "        emt_hist = emt_hist.reshape((len(emt_hist), 1))\n",
    "        cm = np.hstack((cm, emt_hist))\n",
    "\n",
    "    cm = np.delete(cm, 0, axis=1)\n",
    "    cm = np.transpose(cm)\n",
    "\n",
    "    if normalize not in ['true', 'pred', 'all', None]:\n",
    "        raise ValueError(\"normalize must be one of {'true', 'pred', 'all', None}\")\n",
    "\n",
    "    if normalize == 'true':\n",
    "        cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    elif normalize == 'pred':\n",
    "        cm = cm / cm.sum(axis=0, keepdims=True)\n",
    "    elif normalize == 'all':\n",
    "        cm = cm / cm.sum()\n",
    "        # TODO (TASK 1)\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred,normalize='pred')\n",
    "    p = cm.diagonal()\n",
    "    return p\n",
    "    # TODO (TASK 2)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred,normalize='true')\n",
    "    r = cm.diagonal()\n",
    "    return r\n",
    "    # TODO (TASK 2)\n",
    "\n",
    "\n",
    "def false_alarm_rate(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred,normalize='all')\n",
    "    \n",
    "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "    #FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    #TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    FAR = FP/(TP+FP)\n",
    "    return FP/(TP+FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e3da3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 0] \n",
      " [1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.43, 0.69])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_true,'\\n', y_pred)\n",
    "\n",
    "\n",
    "false_alarm_rate(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3805d60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Part I - Confusion matrix\n",
      "------------------------------------------------\n",
      "Unnormalized confusion matrix:\n",
      "[[4.00 9.00]\n",
      " [3.00 4.00]]\n",
      "Matrix sum normalization:\n",
      "[[0.20 0.45]\n",
      " [0.15 0.20]]\n",
      "Row sum normalization:\n",
      "[[0.57 0.69]\n",
      " [0.43 0.31]]\n",
      "Column sum normalization:\n",
      "[[0.31 0.69]\n",
      " [0.43 0.57]]\n",
      "Precision: [0.57 0.31] \n",
      "Recall: [0.31 0.57] \n",
      "False alarm rate: None\n"
     ]
    }
   ],
   "source": [
    "from metrics import confusion_matrix, precision, recall, false_alarm_rate\n",
    "np.random.seed(42)\n",
    "np.set_printoptions(precision=2, floatmode='fixed')\n",
    "\n",
    " # Part I\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Part I - Confusion matrix\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "y_true = np.random.randint(0, 2, 20)\n",
    "y_pred = np.random.randint(0, 2, 20)\n",
    "\n",
    "print(\"Unnormalized confusion matrix:\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "print(\"Matrix sum normalization:\")\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='all')\n",
    "print(cm)\n",
    "print(\"Row sum normalization:\")\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='pred')\n",
    "print(cm)\n",
    "print(\"Column sum normalization:\")\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "print(cm)\n",
    "false_alarm_rate(y_true, y_pred)\n",
    "print('Precision:' , precision(y_true, y_pred), '\\nRecall:',recall(y_true, y_pred), '\\nFalse alarm rate:', false_alarm_rate(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e3fb42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00 9.00]\n",
      " [3.00 4.00]]\n",
      "[0.57 0.31]\n",
      "[0.31 0.57]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true,y_pred))\n",
    "print(precision(y_true,y_pred))\n",
    "print(recall(y_true,y_pred))\n",
    "print(false_alarm_rate(y_true, y_pred))\n",
    "#print(confusion_matrix(y_true, y_pred,normalize='true'))\n",
    "#print(confusion_matrix(y_true, y_pred,normalize='pred'))\n",
    "#print(confusion_matrix(y_true, y_pred,normalize='all'))\n",
    "#print(confusion_matrix(y_true, y_pred,normalize=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d008e585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 9]\n",
      " [3 4]]\n",
      "[0.57 0.31]\n",
      "[0.31 0.57]\n",
      "[0.43 0.69]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Using your data, you can get all the metrics for all the classes at once:\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_true\n",
    "y_prediction = y_pred\n",
    "cnf_matrix = confusion_matrix(y_true, y_prediction)\n",
    "print(cnf_matrix)\n",
    "#[[1 1 3]\n",
    "# [3 2 2]\n",
    "# [1 3 1]]\n",
    "\n",
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "\n",
    "#rint(TNR)\n",
    "print(PPV)\n",
    "print(TPR)\n",
    "#rint(NPV)\n",
    "#rint(FPR)\n",
    "#rint(FNR)\n",
    "print(FDR)\n",
    "#rint(ACC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cac2c6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43956043956043955\n",
      "0.4\n",
      "0.4791208791208791\n",
      "[0.57 0.31]\n",
      "[0.31 0.57]\n",
      "[0.57 0.31]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "print(recall_score(y_true, y_pred, average='macro'))\n",
    "print(precision_score(y_true, y_pred, average='micro'))\n",
    "print(precision_score(y_true, y_pred, average='weighted'))\n",
    "print(precision_score(y_true, y_pred, average=None))\n",
    "print(recall_score(y_true, y_pred, average=None))\n",
    "print(precision_score(y_true, y_pred, average=None, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94d62d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 9],\n",
       "       [3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred,normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b589c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "92947520",
   "metadata": {},
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Computes the confusion matrix from predictions and labels.\n",
    "\n",
    "    The matrix columns represent the real labels and the rows represent the\n",
    "    prediction labels. The confusion matrix is always a 2-D array of shape `[n_labels, n_labels]`,\n",
    "    where `n_labels` is the number of valid labels for a given classification task. Both\n",
    "    prediction and labels must be 1-D arrays of the same shape in order for this\n",
    "    function to work.\n",
    "\n",
    "    Parameters:\n",
    "        y_true: 1-D array of real labels for the classification task.\n",
    "        y_pred: 1-D array of predictions for a given classification.\n",
    "        normalize: One of ['true', 'pred', 'all', None], corresponding to column sum, row sum, matrix sum, or no\n",
    "                   normalization.\n",
    "\n",
    "    Returns:\n",
    "        A 2-D array with shape `[n_labels, n_labels]` representing the confusion\n",
    "        matrix, where `n` is the number of possible labels in the classification\n",
    "        task.\n",
    "    \"\"\"\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    N_ele = np.unique(x)\n",
    "    N_Len = len(N_ele)\n",
    "    cm = np.zeros((N_Len,1))\n",
    "    for i in range(N_Len):\n",
    "        temp = y[x==N_ele[i]]\n",
    "        emt_hist = np.zeros((N_Len,1))\n",
    "        Hist = np.asarray(np.unique(temp, return_counts=True)).T\n",
    "        temp_hist_r1 = Hist[:,0].reshape((len(Hist[:,0]), 1))\n",
    "        temp_hist_r2 = Hist[:,1].reshape((len(Hist[:,0]), 1))\n",
    "        emt_hist[temp_hist_r1[:,0]] = temp_hist_r2\n",
    "        print(emt_hist)\n",
    "        emt_hist = emt_hist.reshape((len(emt_hist), 1))\n",
    "        cm = np.hstack((cm, emt_hist))\n",
    "\n",
    "    cm = np.delete(cm, 0, axis=1)\n",
    "    cm = np.transpose(cm)\n",
    "    return cm\n",
    "\n",
    "y_true = np.array([2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2])\n",
    "y_pred = np.array([0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2])\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c71f7c5b",
   "metadata": {},
   "source": [
    "print(cm[2,:])\n",
    "print((Hist[1,:]))\n",
    "print((cm[2,:]))\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77dd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bb9cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c40b6d0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (recommender_system.py, line 19)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3505\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[32], line 6\u001b[1;36m\n\u001b[1;33m    from recommender_system import MatrixFactorization\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Notebooks_python\\recommender_system.py:19\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.mask = # TODO (TASK 1)\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "import numpy as np\n",
    "\n",
    "from metrics import confusion_matrix, precision, recall, false_alarm_rate\n",
    "from datasets import download_and_prepare\n",
    "from recommender_system import MatrixFactorization\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    np.set_printoptions(precision=2, floatmode='fixed')\n",
    "\n",
    "    # Part I\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"Part I - Confusion matrix\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "    y_true = np.random.randint(0, 2, 20)\n",
    "    y_pred = np.random.randint(0, 2, 20)\n",
    "\n",
    "    print(\"Unnormalized confusion matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    print(\"Matrix sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print(cm)\n",
    "    print(\"Row sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='pred')\n",
    "    print(cm)\n",
    "    print(\"Column sum normalization:\")\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    print(cm)\n",
    "    print(f\"Precision: {precision(y_true, y_pred):.2f}, recall: {recall(y_true, y_pred):.2f}\"\n",
    "          f\", false alarm rate: {false_alarm_rate(y_true, y_pred):.2f}\")\n",
    "\n",
    "    # Part II\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"Part II - Movie Recommender System\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "    X = download_and_prepare('movielens-small', '../datasets')\n",
    "    matrixFactor = MatrixFactorization(X)\n",
    "    r_hat = matrixFactor.fit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a59661dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (recommender_system.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m~\\Notebooks_python\\recommender_system.py:19\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.mask = # TODO (TASK 1)\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84af87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
